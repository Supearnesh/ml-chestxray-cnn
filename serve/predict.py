import os
import numpy as np
import sagemaker_containers
import torch
import torchvision

from PIL import Image
from torchvision import transforms as T

from model import CNNClassifier

def model_fn(model_dir):
    '''Function to load the PyTorch model from the `model_dir` directory.
            
    Args:
        model_dir (str): directory where the model is located
    
    Returns:
        model (CNNClassifier): CNN model
    
    '''

    print('Loading model.')

    # First, load the parameters used to create the model
    model_info = {}
    model_info_path = os.path.join(model_dir, 'model_info.pth')
    with open(model_info_path, 'rb') as f:
        model_info = torch.load(f)

    print('model_info: {}'.format(model_info))

    # Determine the device and construct the model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = CNNClassifier()

    # Load the stored model parameters
    model_path = os.path.join(model_dir, 'model.pth')
    with open(model_path, 'rb') as f:
        model.load_state_dict(torch.load(f))

    model.to(device).eval()

    print('Done loading model.')
    return model


def input_fn(serialized_input_data, content_type):
    '''Function to receive the raw serialized input that has been sent 
    to the model's endpoint, de-serialize it, and make the input 
    available for the inference code.
            
    Args:
        serialized_input_data (str): unprocessed input data of IMDB reviews
        content_type (str): type of input for deserialization
    
    Returns:
        Exception: thrown if content_type not equal to 'application/x-image'
    
    '''

    print('Deserializing the input data.')
    if content_type == 'application/x-image':
        img_bytes = io.BytesIO(serialized_input_data)
        data = Image.open(img_bytes)
        return data
    raise Exception('Requested unsupported ContentType in content_type: ' + content_type)


def output_fn(prediction_output, accept):
    '''Function to take the output of the inference code, serialize this 
    output, and return it to the caller of the model's endpoint.
            
    Args:
        prediction_output (int): prediction generated by the model
        accept (str): accept
    
    Returns:
        prediction_output (str): prediction generated by the model
    
    '''

    print('Serializing the generated output.')
    return str(prediction_output)


def predict_fn(input_data, model):
    '''Function to diagnosis of the provided input data and generate 
    a prediction from the trained model.
            
    Args:
        input_data (Image): input image
        model (CNNClassifier): CNN model
    
    Returns:
        result (int): prediction result for the input image
    
    '''

    print('Prediction for input data.')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    mean = (0.4954160,)
    std = (0.0564721,)

    # Process input_data so that it is ready to be sent to our model
    transform = T.Compose([T.Resize(112),
                           T.Resize((112, 160)),
                           T.ToTensor(),
                           T.Normalize(mean=mean,
                                       std=std)])

    normalized_img = transform(input_data)
    data = normalized_img.unsqueeze(0)
    data = data.to(device)
 
    # Make sure to put the model into evaluation mode
    model.eval()

    # Compute the result of applying the model to the input data
    # The variable `result` should be a numpy array which contains a 
    #   single integer which is either 1 or 0
    with torch.no_grad():
        output = model.forward(data)

    result = np.round(output.numpy())

    return result